{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"../models/kurdish-word2vec-75279.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word_vector(sentence, model, num_features):\n",
    "    \"\"\"Calculate the average word vector for a sentence.\"\"\"\n",
    "    words = sentence.split()\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    num_words = 0\n",
    "    for word in words:\n",
    "        if word in model.wv.key_to_index:\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    return feature_vector / num_words if num_words > 0 else feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [5]\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the saved model\n",
    "model_filename = '../models/sentiment_models/logistic_regression_model.joblib'\n",
    "clf_loaded = load(model_filename)\n",
    "\n",
    "# Assuming `new_text` is your new piece of text to classify\n",
    "new_text = \"دانیا زۆر جوانە\"\n",
    "new_vector = get_average_word_vector(new_text, word2vec_model, 100)  # Use the same function to vectorize\n",
    "\n",
    "# Predict with the loaded model\n",
    "prediction = clf_loaded.predict([new_vector])\n",
    "print(\"Predicted class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12172047, -0.04653458, -0.18058284,  0.30058426, -0.55743825,\n",
       "       -0.17798758, -0.05564431,  0.34794044, -0.1741981 , -0.38840863,\n",
       "       -0.11992711, -0.3396136 , -0.25228134,  0.46261653, -0.6535282 ,\n",
       "       -0.41253218,  0.2542375 ,  0.23918672,  0.25799376,  0.23939458,\n",
       "        0.21854782, -0.04441967,  0.5050352 , -0.24154529,  0.24619746,\n",
       "        0.3260768 ,  0.01387758, -0.05489645, -0.08045173,  0.02822701,\n",
       "       -0.25586423, -0.7574148 ,  0.22554442,  0.05110806,  0.6596611 ,\n",
       "       -0.29157132,  0.47990784, -0.1425718 ,  0.65681314, -0.00419508,\n",
       "       -0.11731908, -0.14273158,  0.11399989,  0.25843352, -0.76641333,\n",
       "        0.30346274, -0.05389855,  0.28187448,  0.35511613, -0.5726515 ,\n",
       "        0.85685015,  0.362743  , -0.12996277, -0.31733507,  0.19744745,\n",
       "        0.27531967, -0.06416368,  0.20083216, -0.07422952, -0.0613633 ,\n",
       "       -0.51389545, -0.22332707, -0.17627916, -0.18248329, -0.20571485,\n",
       "        0.02859752, -0.00485964, -0.09853102, -0.3744912 , -0.29416314,\n",
       "       -0.22571774,  0.40423697,  0.28792548, -0.20487562,  0.8304105 ,\n",
       "       -0.58151954, -0.12195025,  0.05929518, -0.01424   , -0.38413864,\n",
       "       -0.7943509 ,  0.3166896 , -0.31542218,  0.4011281 , -0.45327687,\n",
       "       -0.01197854,  0.7879156 , -0.28994876,  0.7541559 ,  0.2987451 ,\n",
       "        0.14688794, -0.44573984,  0.4730993 , -0.28356484,  0.26556763,\n",
       "       -0.08826225, -0.38641542, -0.6425235 ,  0.02918507, -0.20051077],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
